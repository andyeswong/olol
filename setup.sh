#!/bin/bash
# OLOL Quick Setup Script

echo "ğŸš€ OLOL Quick Setup"
echo "=================="

# Check Python
echo "ğŸ“‹ Checking Python..."
if ! command -v python3 &> /dev/null; then
    echo "âŒ Python 3 not found. Please install Python 3.8+ first."
    exit 1
fi
python3 --version

# Check Ollama
echo "ğŸ“‹ Checking Ollama..."
if ! command -v ollama &> /dev/null; then
    echo "âŒ Ollama not found. Installing..."
    curl -fsSL https://ollama.ai/install.sh | sh
fi
ollama --version

# Install Python dependencies
echo "ğŸ“¦ Installing Python dependencies..."
python3 -m pip install -r requirements.txt

# Install OLOL package
echo "ğŸ“¦ Installing OLOL..."
python3 -m pip install -e .

# Check if models exist
echo "ğŸ“‹ Checking models..."
MODEL_COUNT=$(ollama list | wc -l)
if [ $MODEL_COUNT -le 1 ]; then
    echo "ğŸ“¥ No models found. Downloading a test model..."
    ollama pull llama3.2:3b
fi

# Test installation
echo "ğŸ§ª Testing installation..."
python3 -c "from src.olol.proto import ollama_pb2; print('âœ… OLOL imports working')"

echo ""
echo "âœ… Setup complete!"
echo ""
echo "ğŸš€ To start OLOL:"
echo "  Terminal 1: python3 -m olol server"
echo "  Terminal 2: python3 -m olol proxy --servers localhost:50051"
echo ""
echo "ğŸ“– For detailed setup, see DEPLOYMENT_GUIDE.md"