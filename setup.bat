@echo off
REM OLOL Quick Setup Script for Windows

echo ðŸš€ OLOL Quick Setup
echo ==================

REM Check Python
echo ðŸ“‹ Checking Python...
py --version >nul 2>&1
if errorlevel 1 (
    echo âŒ Python not found. Please install Python 3.8+ first.
    pause
    exit /b 1
)
py --version

REM Check Ollama
echo ðŸ“‹ Checking Ollama...
ollama --version >nul 2>&1
if errorlevel 1 (
    echo âŒ Ollama not found. Please download from https://ollama.ai/download/windows
    pause
    exit /b 1
)
ollama --version

REM Install Python dependencies
echo ðŸ“¦ Installing Python dependencies...
py -m pip install -r requirements.txt

REM Install PyTorch with GPU support
echo ðŸ”¥ Installing PyTorch with CUDA support...
REM For RTX 5090 (Blackwell), use nightly builds with CUDA 12.8
nvidia-smi | findstr "RTX 509" >nul
if %errorlevel% == 0 (
    echo    ðŸŽ¯ RTX 50 series detected - installing nightly PyTorch with CUDA 12.8
    py -m pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128
) else (
    echo    ðŸ”§ Using stable PyTorch with CUDA 12.4
    py -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
)

REM Install OLOL package
echo ðŸ“¦ Installing OLOL...
py -m pip install -e .

REM Check if models exist
echo ðŸ“‹ Checking models...
for /f %%i in ('ollama list ^| find /c /v ""') do set MODEL_COUNT=%%i
if %MODEL_COUNT% leq 1 (
    echo ðŸ“¥ No models found. Downloading a test model...
    ollama pull llama3.2:3b
)

REM Test installation
echo ðŸ§ª Testing installation...
py -c "from src.olol.proto import ollama_pb2; print('âœ… OLOL imports working')"

echo.
echo âœ… Setup complete!
echo.
echo ðŸš€ To start OLOL:
echo   Terminal 1: py -m olol server
echo   Terminal 2: py -m olol proxy --servers localhost:50051
echo.
echo ðŸ“– For detailed setup, see DEPLOYMENT_GUIDE.md
pause