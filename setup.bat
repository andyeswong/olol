@echo off
REM OLOL Quick Setup Script for Windows

echo ğŸš€ OLOL Quick Setup
echo ==================

REM Check Python
echo ğŸ“‹ Checking Python...
py --version >nul 2>&1
if errorlevel 1 (
    echo âŒ Python not found. Please install Python 3.8+ first.
    pause
    exit /b 1
)
py --version

REM Check Ollama
echo ğŸ“‹ Checking Ollama...
ollama --version >nul 2>&1
if errorlevel 1 (
    echo âŒ Ollama not found. Please download from https://ollama.ai/download/windows
    pause
    exit /b 1
)
ollama --version

REM Install Python dependencies
echo ğŸ“¦ Installing Python dependencies...
py -m pip install -r requirements.txt

REM Install OLOL package
echo ğŸ“¦ Installing OLOL...
py -m pip install -e .

REM Check if models exist
echo ğŸ“‹ Checking models...
for /f %%i in ('ollama list ^| find /c /v ""') do set MODEL_COUNT=%%i
if %MODEL_COUNT% leq 1 (
    echo ğŸ“¥ No models found. Downloading a test model...
    ollama pull llama3.2:3b
)

REM Test installation
echo ğŸ§ª Testing installation...
py -c "from src.olol.proto import ollama_pb2; print('âœ… OLOL imports working')"

echo.
echo âœ… Setup complete!
echo.
echo ğŸš€ To start OLOL:
echo   Terminal 1: py -m olol server
echo   Terminal 2: py -m olol proxy --servers localhost:50051
echo.
echo ğŸ“– For detailed setup, see DEPLOYMENT_GUIDE.md
pause